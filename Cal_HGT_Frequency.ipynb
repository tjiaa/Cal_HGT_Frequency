{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from Bio import SeqIO\n",
    "from itertools import combinations\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path='/node05/program/Gallinarum_Project/Code_test/SG_Analyse-code-main/Cal_HGT_Frequency/'\n",
    "ARG_name='tet(A)_6'\n",
    "inputname='example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(work_path+'Extract'):\n",
    "    Extract_fasta_file=work_path+'Extract/'\n",
    "else:\n",
    "    os.mkdir(work_path+'Extract/')\n",
    "    Extract_fasta_file=work_path+'Extract/'\n",
    "\n",
    "\n",
    "if os.path.exists(work_path+'Motifi_Extract_Fasta'):\n",
    "    Motifi=work_path+'Motifi_Extract_Fasta/'\n",
    "else:\n",
    "    os.mkdir(work_path+'Motifi_Extract_Fasta/')\n",
    "    Motifi=work_path+'Motifi_Extract_Fasta/'\n",
    "\n",
    "\n",
    "if os.path.exists(work_path+ARG_name+'_list'):\n",
    "    List_path=work_path+ARG_name+'_list/'\n",
    "else:\n",
    "    os.mkdir(work_path+ARG_name+'_list/')\n",
    "    List_path=work_path+ARG_name+'_list/'\n",
    "\n",
    "\n",
    "if os.path.exists(work_path+'abricate_file/'):\n",
    "    file_path=work_path+'abricate_file/'\n",
    "else:\n",
    "    os.mkdir(work_path+'abricate_file/')\n",
    "    file_path=work_path+'abricate_file/'\n",
    "\n",
    "\n",
    "if os.path.exists(work_path+'fasta_file/'):\n",
    "    fasta_path=work_path+'fasta_file/'\n",
    "else:\n",
    "    os.mkdir(work_path+'fasta_file/')\n",
    "    fasta_path=work_path+'fasta_file/'\n",
    "\n",
    "inputname=work_path+inputname+'/'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_contig_names(input_file, output_file, prefix):\n",
    "    with open(input_file, 'r') as f_in, open(output_file, 'w') as f_out:\n",
    "        for line in f_in:\n",
    "            if line.startswith('>'):\n",
    "                new_contig_name = f\">{prefix}\\n\"\n",
    "                f_out.write(new_contig_name)\n",
    "            else:\n",
    "                f_out.write(line)\n",
    "\n",
    "def merge_fasta_files(input_folder, output_file):\n",
    "    with open(output_file, 'w') as out_handle:\n",
    "        for filename in os.listdir(input_folder):\n",
    "            if filename.endswith('.fasta'):\n",
    "                file_path = os.path.join(input_folder, filename)\n",
    "                for record in SeqIO.parse(file_path, 'fasta'):\n",
    "                    SeqIO.write(record, out_handle, 'fasta')\n",
    "\n",
    "#For intercepting reverse complementary\n",
    "def rev(seq):\n",
    "    base_trans = {'A':'T', 'C':'G', 'T':'A', 'G':'C', 'a':'t', 'c':'g', 't':'a', 'g':'c'}\n",
    "    rev_seq = list(reversed(seq))\n",
    "    rev_seq_list = [base_trans[k] for k in rev_seq]\n",
    "    rev_seq = ''.join(rev_seq_list)\n",
    "    return(rev_seq)\n",
    "\n",
    "def extract_fasta(input, list, output):\n",
    "    seq_file = {}\n",
    "    with open(input, 'r') as input_fasta:\n",
    "        for line in input_fasta:\n",
    "            line = line.strip()\n",
    "            if line[0] == '>':\n",
    "                seq_id = line.split()[0]\n",
    "                seq_file[seq_id] = ''\n",
    "            else:\n",
    "                seq_file[seq_id] += line\n",
    "    input_fasta.close()\n",
    "\n",
    "    list_dict = {}\n",
    "    with open(list, 'r') as list_file:\n",
    "        for line in list_file:\n",
    "            if line.strip():\n",
    "                line = line.strip().split('\\t')\n",
    "                list_dict[line[0]] = [line[1], int(line[2]) - 1, int(line[3]), line[4]]\n",
    "    list_file.close()\n",
    "\n",
    "    output_fasta = open(output, 'w')\n",
    "    for key,value in list_dict.items():\n",
    "        print('>' + key, file = output_fasta)\n",
    "        seq = seq_file['>' + value[0]][value[1]:value[2]]\n",
    "        if value[3] == '+':\n",
    "            print(seq, file = output_fasta)\n",
    "        elif value[3] == '-':\n",
    "            seq = rev(seq)\n",
    "            print(seq, file = output_fasta)\n",
    "    output_fasta.close()\n",
    "    \n",
    "def remove_duplicates(strings):\n",
    "    seen_pairs = set()    \n",
    "    result = []\n",
    "    for string in strings:\n",
    "        parts = string.split('-')\n",
    "        pair = tuple(sorted(parts))\n",
    "        if pair not in seen_pairs:\n",
    "            seen_pairs.add(pair)\n",
    "            result.append(string)\n",
    "    return result\n",
    "\n",
    "def remove_duplicates2(strings):\n",
    "    result = []\n",
    "    for string in strings:\n",
    "        parts = string.split('-')\n",
    "        if len(parts) == 2 and parts[0] != parts[1]:\n",
    "            result.append(string)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process_File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start process 30 files\n"
     ]
    }
   ],
   "source": [
    "inputname_list=os.listdir(inputname)\n",
    "inputname_list_fna=[x for x in inputname_list if x.endswith('.fasta')]\n",
    "inputname_list_txt=[x for x in inputname_list if x.endswith('.tabular')]\n",
    "if len(inputname_list_fna) == len(inputname_list_txt):\n",
    "    print('Start process '+ str(len(inputname_list_txt)) + ' files' )\n",
    "for i in inputname_list_txt:\n",
    "    shutil.copy(inputname+i,file_path)\n",
    "for i in inputname_list_fna:\n",
    "    shutil.copy(inputname+i,fasta_path)\n",
    "#####txtfile+filename####\n",
    "for i in inputname_list_txt:\n",
    "    i_file=pd.read_csv(file_path+i,sep='\\t')\n",
    "    pending_item_length=i_file.shape[0]\n",
    "    i_name=i.replace('tabular','fasta')\n",
    "    pending_item=[i_name]*pending_item_length\n",
    "    i_file['#FILE']=pending_item\n",
    "    i_file.to_csv(file_path+i,sep='\\t')\n",
    "###check_process\n",
    "# for i in inputname_list_txt:\n",
    "#     check_process=pd.read_csv(file_path+i,sep='\\t')\n",
    "#     check_process=check_process[check_process['Best_Hit_ARO']==ARG_name]\n",
    "#     if check_process.shape[0] != 1:\n",
    "#         os.remove(file_path+i)\n",
    "# print('Check_process_complete, '+str(len(os.listdir(file_path)))+ ' remain')\n",
    "\n",
    "merged_txt=work_path+'All_txt.txt'\n",
    "\n",
    "with open(merged_txt, 'w') as outfile:\n",
    "    for filename in os.listdir(file_path):\n",
    "        if filename.endswith('.tabular'):\n",
    "            temp_file_path = os.path.join(file_path, filename)\n",
    "            with open(temp_file_path, 'r') as infile:\n",
    "                outfile.write(infile.read())\n",
    "\n",
    "\n",
    "file=pd.read_csv(merged_txt,sep='\\t')\n",
    "file=file[file['GENE']==ARG_name]\n",
    "file=file.drop(\"Unnamed: 0\", axis=1)\n",
    "file.to_csv(work_path+'Target_ARG_summary.csv',index=False)\n",
    "file=pd.read_csv('Target_ARG_summary.csv')\n",
    "file_length=file.shape[0]\n",
    "os.remove(merged_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "while counter < file_length:\n",
    "    txt_out=[]\n",
    "    temp_file=file[file.index==counter]\n",
    "    fasta_list_filename=temp_file['#FILE'].to_list()[0]\n",
    "    ARG_name=temp_file['GENE'].to_list()[0]\n",
    "    SEQUENCE=temp_file['SEQUENCE'].to_list()[0]\n",
    "    START=temp_file['START'].to_list()[0]\n",
    "    START=str(START)\n",
    "    END=temp_file['END'].to_list()[0]\n",
    "    END=str(END)\n",
    "    STRAND=temp_file['STRAND'].to_list()[0]\n",
    "    txt_out.append(SEQUENCE)\n",
    "    txt_out.append(START)\n",
    "    txt_out.append(END)\n",
    "    txt_out.append(STRAND)\n",
    "\n",
    "    if len(txt_out)==4:\n",
    "        txt_out=pd.DataFrame(txt_out)\n",
    "        txt_out=txt_out.T\n",
    "        txt_out.to_csv(List_path+fasta_list_filename+'_'+str(counter),sep='\\t',header=False)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAL00737.fasta\n",
      "Extracting SAL00737.fasta.fasta_27\n",
      "SAL_PA6310AA.fasta\n",
      "Extracting SAL_PA6310AA.fasta.fasta_1\n",
      "SAL_PA7971AA.fasta\n",
      "Extracting SAL_PA7971AA.fasta.fasta_4\n",
      "SAL00717.fasta\n",
      "Extracting SAL00717.fasta.fasta_9\n",
      "SAL00712.fasta\n",
      "Extracting SAL00712.fasta.fasta_3\n",
      "SAL_PA7695AA.fasta\n",
      "Extracting SAL_PA7695AA.fasta.fasta_17\n",
      "SAL_PA7976AA.fasta\n",
      "Extracting SAL_PA7976AA.fasta.fasta_19\n",
      "SAL00747.fasta\n",
      "Extracting SAL00747.fasta.fasta_7\n",
      "SAL_PA7725AA.fasta\n",
      "Extracting SAL_PA7725AA.fasta.fasta_0\n",
      "SAL_PA7703AA.fasta\n",
      "Extracting SAL_PA7703AA.fasta.fasta_12\n",
      "ERS2630744.fasta\n",
      "Extracting ERS2630744.fasta.fasta_11\n",
      "SAL00714.fasta\n",
      "Extracting SAL00714.fasta.fasta_14\n",
      "SAL00711.fasta\n",
      "Extracting SAL00711.fasta.fasta_20\n",
      "SAL00734.fasta\n",
      "Extracting SAL00734.fasta.fasta_10\n",
      "SAL00740.fasta\n",
      "Extracting SAL00740.fasta.fasta_26\n",
      "SAL_PA7707AA.fasta\n",
      "Extracting SAL_PA7707AA.fasta.fasta_23\n",
      "ERS2630811.fasta\n",
      "Extracting ERS2630811.fasta.fasta_18\n",
      "SAL_PA7753AA.fasta\n",
      "Extracting SAL_PA7753AA.fasta.fasta_25\n",
      "SAL_PA7716AA.fasta\n",
      "Extracting SAL_PA7716AA.fasta.fasta_16\n",
      "SAL_PA7759AA.fasta\n",
      "Extracting SAL_PA7759AA.fasta.fasta_2\n",
      "SAL00713.fasta\n",
      "Extracting SAL00713.fasta.fasta_15\n",
      "SAL_PA7970AA.fasta\n",
      "Extracting SAL_PA7970AA.fasta.fasta_24\n",
      "SAL_PA7752AA.fasta\n",
      "Extracting SAL_PA7752AA.fasta.fasta_29\n",
      "SAL00741.fasta\n",
      "Extracting SAL00741.fasta.fasta_5\n",
      "SAL_PA7737AA.fasta\n",
      "Extracting SAL_PA7737AA.fasta.fasta_13\n",
      "SAL_PA0702AA.fasta\n",
      "Extracting SAL_PA0702AA.fasta.fasta_28\n",
      "SAL_UA3243AA.fasta\n",
      "Extracting SAL_UA3243AA.fasta.fasta_22\n",
      "SAL00745.fasta\n",
      "Extracting SAL00745.fasta.fasta_8\n",
      "SAL_PA7741AA.fasta\n",
      "Extracting SAL_PA7741AA.fasta.fasta_21\n",
      "SAL_PA7730AA.fasta\n",
      "Extracting SAL_PA7730AA.fasta.fasta_6\n"
     ]
    }
   ],
   "source": [
    "List_path_file=os.listdir(List_path)\n",
    "for i in List_path_file:\n",
    "    last_underscore_index=i.rfind('.fasta_')\n",
    "    real_fasta_name=i[:last_underscore_index]\n",
    "    print(real_fasta_name)\n",
    "\n",
    "    print('Extracting '+i)\n",
    "    input_fasta=fasta_path+real_fasta_name\n",
    "    list_file=List_path+i\n",
    "    output=Extract_fasta_file+i\n",
    "    extract_fasta(input_fasta,list_file,output)\n",
    "\n",
    "fastas=os.listdir(Extract_fasta_file)\n",
    "for i in fastas:\n",
    "    contig_name=i.replace('.fasta','')\n",
    "    modify_contig_names(Extract_fasta_file+i, Motifi+i,contig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Combine Mutil Fasta Files########\n",
    "Motified_fastas=os.listdir(Motifi)\n",
    "temp_Motified=[]\n",
    "for i in Motified_fastas:\n",
    "    last_underscore_index=i.rfind('_')\n",
    "    temp_temp_Motified=i[:last_underscore_index]\n",
    "    temp_Motified.append(temp_temp_Motified)\n",
    "\n",
    "set_temp_Motified=list(set(temp_Motified))\n",
    "for i in set_temp_Motified:\n",
    "\n",
    "    temp_count=temp_Motified.count(i)\n",
    "\n",
    "    if temp_count > 1:\n",
    "        temp_Motified_file_list=[x for x in Motified_fastas if x.startswith(i)]\n",
    "\n",
    "        with open(Motifi+i, 'w') as outfile:\n",
    "            for ii in temp_Motified_file_list:\n",
    "                with open(Motifi+ii, 'r') as infile:\n",
    "                    for line in infile:\n",
    "                        outfile.write(line)\n",
    "    else:\n",
    "        temp_Motified_file_list=[x for x in Motified_fastas if x.startswith(i)][0]\n",
    "        os.rename(Motifi+temp_Motified_file_list,Motifi+i)\n",
    "output_file=ARG_name+' merged.fasta'\n",
    "merge_fasta_files(Motifi, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Blastn file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/node05/program/Gallinarum_Project/Code_test/SG_Analyse-code-main/Cal_HGT_Frequency/blastn/merged_DB/merged.fasta'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(work_path+'blastn'):\n",
    "    blastn_path=work_path+'blastn'\n",
    "else:\n",
    "    os.mkdir(work_path+'blastn')\n",
    "    blastn_path=work_path+'blastn'\n",
    "\n",
    "if os.path.exists(work_path+output_file):\n",
    "    shutil.move(work_path+output_file,blastn_path)\n",
    "else:\n",
    "    print(output_file, \" Missing\")\n",
    "\n",
    "if os.path.exists(Motifi):\n",
    "    shutil.move(Motifi,blastn_path)\n",
    "else:\n",
    "    print(\"Motifi folder Missing\")\n",
    "\n",
    "if os.path.exists(work_path+'blastn.sh'):\n",
    "    shutil.copy(work_path+'blastn.sh',blastn_path)\n",
    "else:\n",
    "    print(\"Blatn Script Missing\")\n",
    "\n",
    "os.mkdir(blastn_path+'/OUT')\n",
    "os.mkdir(blastn_path+'/merged_DB')\n",
    "os.rename(blastn_path+'/'+output_file, blastn_path+'/'+'merged.fasta')\n",
    "shutil.move(blastn_path+'/merged.fasta',blastn_path+'/merged_DB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building blastn indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blastn DB Run Success\n",
      "\n",
      "\n",
      "Building a new DB, current time: 06/13/2024 22:53:05\n",
      "New DB name:   /node05/program/Gallinarum_Project/Code_test/SG_Analyse-code-main/Cal_HGT_Frequency/blastn/merged_DB/merged\n",
      "New DB title:  merged.fasta\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 3000000000B\n",
      "Adding sequences from FASTA; added 30 sequences in 0.00123286 seconds.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "working_directory=blastn_path+'/merged_DB'\n",
    "command = [\"makeblastdb\", \"-in\", \"merged.fasta\", \"-dbtype\", \"nucl\", \"-out\", \"merged\", \"-parse_seqids\"]\n",
    "result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=working_directory)\n",
    "if result.returncode == 0:\n",
    "    print(\"Blastn DB Run Success\")\n",
    "    print(result.stdout.decode())\n",
    "else:\n",
    "    print(\"Blastn DB Run Failed\")\n",
    "    print(result.stderr.decode())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Blastn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blastn Run Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "working_directory=blastn_path\n",
    "command = [\"sh\", \"blastn.sh\"]\n",
    "result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=working_directory)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"Blastn Run Complete\")\n",
    "    print(result.stdout.decode())\n",
    "else:\n",
    "    print(\"Blastn Run Failed\")\n",
    "    print(result.stderr.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate HGT Frequent Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Combined\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/node05/program/Gallinarum_Project/Code_test/SG_Analyse-code-main/Cal_HGT_Frequency/Final_blastn_merged.txt'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_directory=blastn_path+'/OUT'\n",
    "command = [\"cat\", \"*.txt\", \">\", \"Final_blastn_merged.txt\"]\n",
    "result = subprocess.run(\" \".join(command), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=working_directory)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"File Combined\")\n",
    "    print(result.stdout.decode())\n",
    "else:\n",
    "    print(\"File Combined Failed\")\n",
    "    print(result.stderr.decode())\n",
    "\n",
    "shutil.move(blastn_path+'/OUT/Final_blastn_merged.txt',work_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=pd.read_csv('Final_blastn_merged.txt',sep='\\t',header=None)\n",
    "column=['name1','name2','name3','name4','name5','name6','name7','name8','name9','name10',\n",
    "        'name11','name12','name13','name14']\n",
    "file.columns=column\n",
    "file_length2=file.shape[0]\n",
    "x_col=['-']*file_length2\n",
    "file['x']=x_col\n",
    "file['y']=file.apply(lambda row: ''.join(row[['name1', 'x', 'name2']]), axis=1)\n",
    "file_name1=list(set(file['name1'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Y=[]\n",
    "All_verify=[]\n",
    "for i in file_name1:\n",
    "    temp_file=file[file['name1']==i]\n",
    "    new_index=i+'-'+i\n",
    "    temp_file2=temp_file[temp_file['y']==new_index]\n",
    "    temp_file2_name4=temp_file2['name4'].to_list()\n",
    "    max_value = max(temp_file2_name4)\n",
    "    temp_file3=temp_file[temp_file['name4']==max_value]\n",
    "    temp_file3=temp_file3[temp_file3['name3'] ==  100]\n",
    "    ready_to_depulicate=temp_file3['y'].to_list()\n",
    "    verfy=temp_file3['name3'].to_list()\n",
    "    for ii in ready_to_depulicate:\n",
    "        All_Y.append(ii)\n",
    "    for iii in verfy:\n",
    "        All_verify.append(iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_1=remove_duplicates(All_Y)\n",
    "filtered_2=remove_duplicates2(filtered_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "435.0\n",
      "HGT Frequency for  tet(A)_6 is: 0.35\n"
     ]
    }
   ],
   "source": [
    "# final_all_all=file_length*file_length  \n",
    "final_all_count=len(filtered_2)\n",
    "print(final_all_count)\n",
    "final_all_all=(1+(file_length-1))*((file_length-1)/2)\n",
    "print(final_all_all) \n",
    "HGT_Frequency=final_all_count/final_all_all\n",
    "HGT_Frequency=round(HGT_Frequency,2)\n",
    "print('HGT Frequency for ', ARG_name, 'is:', HGT_Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(work_path+'blastn')\n",
    "# shutil.rmtree(work_path+'Extract')\n",
    "# shutil.rmtree(work_path+'fasta_file')\n",
    "# shutil.rmtree(work_path+'abricate_file')\n",
    "# shutil.rmtree(work_path+ARG_name+'_list/')\n",
    "# os.remove(work_path+'Final_blastn_merged.txt')\n",
    "# os.remove(work_path+'Target_ARG_summary.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jia_node05",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
